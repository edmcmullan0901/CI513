import pandas as pd
import os

# Load, merge, and return the dataset
def load_and_merge_data(
    train_path='data/train.csv',
    weather_path='data/weather_train.csv',
    metadata_path='data/building_metadata.csv'):

    train_df = pd.read_csv(train_path, parse_dates=['timestamp'])
    weather_df = pd.read_csv(weather_path, parse_dates=['timestamp'])
    metadata_df = pd.read_csv(metadata_path)

    df = train_df.merge(metadata_df, on='building_id', how='left')
    df = df.merge(weather_df, on=['site_id', 'timestamp'], how='left')

    return df

# Clean and filter dataset
def clean_data(df):
    df = df.copy()
    df = df.dropna(subset=['air_temperature', 'meter_reading'])
    df = df[df['meter'] == 0] #remove data with 0 readings
    df = df[df['meter_reading'] > 1]
    df = df[df['meter_reading'] < df['meter_reading'].quantile(0.99)]
    return df

def preprocess_pipeline():
    df = load_and_merge_data()
    cleaned_df = clean_data(df)
    return cleaned_df

if __name__ == "__main__":
    processed_df = preprocess_pipeline()
    os.makedirs("data", exist_ok=True)  # check output folder exists
    processed_df.to_csv("data/processed_data.csv", index=False)
